{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a71796",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 问题描述\n",
    "\n",
    "Suppose you are starting a company that grows and sells wild mushrooms. \n",
    "- Since not all mushrooms are edible, you'd like to be able to tell whether a given mushroom is edible or poisonous based on it's physical attributes\n",
    "- You have some existing data that you can use for this task. \n",
    "\n",
    "Can you use the data to help you identify which mushrooms can be sold safely? \n",
    "\n",
    "Note: The dataset used is for illustrative purposes only. It is not meant to be a guide on identifying edible mushrooms.\n",
    "\n",
    "\n",
    "\n",
    "<a name=\"3\"></a>\n",
    "## 数据集\n",
    "\n",
    "You will start by loading the dataset for this task. The dataset you have collected is as follows:\n",
    "\n",
    "|                                                     | Cap Color | Stalk Shape | Solitary | Edible |\n",
    "|:---------------------------------------------------:|:---------:|:-----------:|:--------:|:------:|\n",
    "| <img src=\"images/0.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |   Tapering  |    Yes   |    1   |\n",
    "| <img src=\"images/1.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    Yes   |    1   |\n",
    "| <img src=\"images/2.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    No    |    0   |\n",
    "| <img src=\"images/3.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    No    |    0   |\n",
    "| <img src=\"images/4.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |   Tapering  |    Yes   |    1   |\n",
    "| <img src=\"images/5.png\" alt=\"drawing\" width=\"50\"/> |    Red    |   Tapering  |    Yes   |    0   |\n",
    "| <img src=\"images/6.png\" alt=\"drawing\" width=\"50\"/> |    Red    |  Enlarging  |    No    |    0   |\n",
    "| <img src=\"images/7.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    Yes   |    1   |\n",
    "| <img src=\"images/8.png\" alt=\"drawing\" width=\"50\"/> |    Red    |   Tapering  |    No    |    1   |\n",
    "| <img src=\"images/9.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    No    |    0   |\n",
    "\n",
    "\n",
    "-  You have 10 examples of mushrooms. For each example, you have\n",
    "    - Three features\n",
    "        - Cap Color (`Brown` or `Red`),\n",
    "        - Stalk Shape (`Tapering (as in \\/)` or `Enlarging (as in /\\)`), and\n",
    "        - Solitary (`Yes` or `No`)\n",
    "    - Label\n",
    "        - Edible (`1` indicating yes or `0` indicating poisonous)\n",
    "\n",
    "<a name=\"3.1\"></a>\n",
    "### 3.1 One hot encoded dataset\n",
    "For ease of implementation, we have one-hot encoded the features (turned them into 0 or 1 valued features)\n",
    "\n",
    "|                                                    | Brown Cap | Tapering Stalk Shape | Solitary | Edible |\n",
    "|:--------------------------------------------------:|:---------:|:--------------------:|:--------:|:------:|\n",
    "| <img src=\"images/0.png\" alt=\"drawing\" width=\"50\"/> |     1     |           1          |     1    |    1   |\n",
    "| <img src=\"images/1.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     1    |    1   |\n",
    "| <img src=\"images/2.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
    "| <img src=\"images/3.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
    "| <img src=\"images/4.png\" alt=\"drawing\" width=\"50\"/> |     1     |           1          |     1    |    1   |\n",
    "| <img src=\"images/5.png\" alt=\"drawing\" width=\"50\"/> |     0     |           1          |     1    |    0   |\n",
    "| <img src=\"images/6.png\" alt=\"drawing\" width=\"50\"/> |     0     |           0          |     0    |    0   |\n",
    "| <img src=\"images/7.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     1    |    1   |\n",
    "| <img src=\"images/8.png\" alt=\"drawing\" width=\"50\"/> |     0     |           1          |     0    |    1   |\n",
    "| <img src=\"images/9.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4fd6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af56d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set\n",
    "X_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
    "y_train = np.array([1,1,0,0,1,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d354d87c",
   "metadata": {},
   "source": [
    "### Check the dimension of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4b44a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3), (10,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e11f2",
   "metadata": {},
   "source": [
    "### Basic Function\n",
    "entropy\n",
    "$$H(p_1) = -p_1 \\text{log}_2(p_1) - (1- p_1) \\text{log}_2(1- p_1)$$\n",
    "这个公式类似交叉熵，衡量样本的纯度，为1或0标签的样本数目越多熵(entropy)越小\n",
    "其中，$p_1$ 是标签为1在总样本的占比，$0 \\text{log}_2(0) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "658e0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    \"\"\"\n",
    "    Compute the entropy of a label array.\n",
    "    \n",
    "    Parameters:\n",
    "    y (numpy array): Array of labels (0s and 1s).\n",
    "    \n",
    "    Returns:\n",
    "    float: Entropy value.\n",
    "    \"\"\"\n",
    "    if (len(y) == 0):\n",
    "        return 0\n",
    "    p1 = np.sum(y)/len(y)\n",
    "    p0 = 1 - p1\n",
    "    if p1 == 0 or p1 == 1:\n",
    "        return 0\n",
    "    return -p1 * np.log2(p1) - p0 * np.log2(p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec821ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling with replacement\n",
    "def sampling(X_train:np.ndarray,y_train:np.ndarray)->tuple[np.ndarray,np.ndarray]:\n",
    "    n = X_train.shape[0]\n",
    "    indices = np.random.choice(n, size=n, replace=True)\n",
    "    \"\"\"\n",
    "    sampling between 0 to n-1, size=n, with replacement(放回抽样)\n",
    "    \n",
    "    \"\"\"\n",
    "    return X_train[indices],y_train[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1502e097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the node based on the feature seleted\n",
    "def split_node(X:np.ndarray,y:np.ndarray,feature_index:int)->tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split the dataset based on a feature index.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy array): Feature dataset.\n",
    "    y (numpy array): Labels.\n",
    "    feature_index (int): Index of the feature to split on.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Four numpy arrays - X_left, y_left, X_right, y_right\n",
    "    \"\"\"\n",
    "    X_left = X[X[:, feature_index] == 0]\n",
    "    y_left = y[X[:, feature_index] == 0]\n",
    "    X_right = X[X[:, feature_index] == 1]\n",
    "    y_right = y[X[:, feature_index] == 1]\n",
    "    \n",
    "    return X_left, y_left, X_right, y_right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae218f57",
   "metadata": {},
   "source": [
    "## Information Gain(== reduction of the entropy)\n",
    "\n",
    "\n",
    "$$\\text{Information Gain} = H(p_1^\\text{node})- (w^{\\text{left}}H(p_1^\\text{left}) + w^{\\text{right}}H(p_1^\\text{right}))$$\n",
    "\n",
    "where \n",
    "- $H(p_1^\\text{node})$ is entropy at the node \n",
    "- $H(p_1^\\text{left})$ and $H(p_1^\\text{right})$ are the entropies at the left and the right branches resulting from the split\n",
    "- $w^{\\text{left}}$ and $w^{\\text{right}}$ are the proportion of examples at the left and right branch, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43be16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate information gain\n",
    "def information_gain(y_father:np.array,y_left:np.ndarray,y_right:np.ndarray)->float:\n",
    "    father_size = len(y_father)\n",
    "    w_left = len(y_left)/father_size\n",
    "    w_right = len(y_right)/father_size\n",
    "    return entropy(y_father) - (w_left * entropy(y_left) + w_right * entropy(y_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9ef2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursively split the dataset\n",
    "def recursive_split(X:np.ndarray,y:np.ndarray,depth:int,max_depth:int)->dict:\n",
    "    n_samples, n_features = X.shape\n",
    "    # If all labels are the same, return a leaf node\n",
    "    if len(set(y)) == 1: # len(y)?? 返回唯一标签的数量，set是python集合，可以去重，如果只有一种，则只有一个元素\n",
    "        return {'type': 'leaf', 'class': y[0]}\n",
    "    \n",
    "    # If maximum depth is reached or no samples left, return a leaf node with majority class\n",
    "    if depth == max_depth or n_samples == 0:\n",
    "        majority_class = np.bincount(y).argmax()\n",
    "        return {'type': 'leaf', 'class': majority_class}\n",
    "    \n",
    "    # Find the best feature to split on\n",
    "    best_gain = -1\n",
    "    best_feature = None\n",
    "    best_splits = None\n",
    "    \n",
    "    # 这里允许了特征的重复使用！！！\n",
    "    for feature_index in range(n_features):\n",
    "        X_left, y_left, X_right, y_right = split_node(X, y, feature_index)\n",
    "        gain = information_gain(y, y_left, y_right)\n",
    "        \n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_feature = feature_index\n",
    "            best_splits = (X_left, y_left, X_right, y_right)\n",
    "    \n",
    "    # If no information gain, return a leaf node with majority class\n",
    "    if best_gain == 0:\n",
    "        majority_class = np.bincount(y).argmax()\n",
    "        return {'type': 'leaf', 'class': majority_class}\n",
    "    \n",
    "    # Recursively split the left and right nodes\n",
    "    X_left, y_left, X_right, y_right = best_splits\n",
    "    left_subtree = recursive_split(X_left, y_left, depth + 1, max_depth)\n",
    "    right_subtree = recursive_split(X_right, y_right, depth + 1, max_depth)\n",
    "    \n",
    "    return {\n",
    "        'type': 'node',\n",
    "        'feature_index': best_feature,\n",
    "        'left': left_subtree,\n",
    "        'right': right_subtree\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b7583fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_split_noReuse(X:np.ndarray, y:np.ndarray, depth:int, max_depth:int, used_features:set=None)->dict:\n",
    "    n_samples, n_features = X.shape\n",
    "    if used_features is None:\n",
    "        used_features = set()\n",
    "    \n",
    "    # 如果所有标签相同，返回叶节点\n",
    "    if len(set(y)) == 1:\n",
    "        return {'type': 'leaf', 'class': y[0]}\n",
    "    \n",
    "    # 如果达到最大深度或没有样本，返回多数类叶节点\n",
    "    if depth == max_depth or n_samples == 0:\n",
    "        majority_class = np.bincount(y).argmax()\n",
    "        return {'type': 'leaf', 'class': majority_class}\n",
    "    \n",
    "    best_gain = -1\n",
    "    best_feature = None\n",
    "    best_splits = None\n",
    "    \n",
    "    # 只考虑未使用过的特征\n",
    "    available_features = [i for i in range(n_features) if i not in used_features]\n",
    "    \n",
    "    for feature_index in available_features:\n",
    "        X_left, y_left, X_right, y_right = split_node(X, y, feature_index)\n",
    "        gain = information_gain(y, y_left, y_right)\n",
    "        \n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_feature = feature_index\n",
    "            best_splits = (X_left, y_left, X_right, y_right)\n",
    "    \n",
    "    # 如果没有信息增益或没有可用特征，返回叶节点\n",
    "    if best_gain == 0 or not available_features:\n",
    "        majority_class = np.bincount(y).argmax()\n",
    "        return {'type': 'leaf', 'class': majority_class}\n",
    "    \n",
    "    # 递归分裂，将当前使用的特征添加到已使用集合中\n",
    "    X_left, y_left, X_right, y_right = best_splits\n",
    "    new_used_features = used_features | {best_feature}\n",
    "    \n",
    "    left_subtree = recursive_split_noReuse(X_left, y_left, depth + 1, max_depth, new_used_features)\n",
    "    right_subtree = recursive_split_noReuse(X_right, y_right, depth + 1, max_depth, new_used_features)\n",
    "    \n",
    "    return {\n",
    "        'type': 'node',\n",
    "        'feature_index': best_feature,\n",
    "        'left': left_subtree,\n",
    "        'right': right_subtree\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1ff48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, n_trees:int=10, max_depth:int=5):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X:np.ndarray, y:np.ndarray):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            X_sample, y_sample = sampling(X, y)\n",
    "            tree = recursive_split(X_sample, y_sample, depth=0, max_depth=self.max_depth)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict_single(self, x:np.ndarray, tree:dict)->int: # 其中x是单个样本，tree是决策树\n",
    "        if tree['type'] == 'leaf':\n",
    "            return tree['class']\n",
    "        feature_value = x[tree['feature_index']]\n",
    "        if feature_value == 0:\n",
    "            return self.predict_single(x, tree['left'])\n",
    "        else:\n",
    "            return self.predict_single(x, tree['right'])\n",
    "    def predict(self, X:np.ndarray)->np.ndarray:\n",
    "        predictions = np.array([self.predict_single(x, tree) for x in X for tree in self.trees])# 列表初始化\n",
    "        predictions = predictions.reshape(X.shape[0], self.n_trees)\n",
    "        final_predictions = np.array([np.bincount(row).argmax() for row in predictions])\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa7b5c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'node',\n",
       "  'feature_index': 2,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 1,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 0,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 2,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 0,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(1)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(0)}},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 0,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 0,\n",
       "  'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 1,\n",
       "  'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "  'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 0,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 1,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'node',\n",
       "    'feature_index': 2,\n",
       "    'left': {'type': 'leaf', 'class': np.int64(1)},\n",
       "    'right': {'type': 'leaf', 'class': np.int64(0)}}},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 1,\n",
       "  'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 0,\n",
       "   'left': {'type': 'node',\n",
       "    'feature_index': 2,\n",
       "    'left': {'type': 'leaf', 'class': np.int64(1)},\n",
       "    'right': {'type': 'leaf', 'class': np.int64(0)}},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 0,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(1)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(0)}},\n",
       "  'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 1,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 0,\n",
       "   'left': {'type': 'node',\n",
       "    'feature_index': 2,\n",
       "    'left': {'type': 'leaf', 'class': np.int64(1)},\n",
       "    'right': {'type': 'leaf', 'class': np.int64(0)}},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 1,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       "  'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 1,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(1)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(0)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 2,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 1,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       "  'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 2,\n",
       "  'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "  'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 1,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       "  'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 1,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       "  'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 0,\n",
       "  'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 1,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 0,\n",
       "   'left': {'type': 'node',\n",
       "    'feature_index': 2,\n",
       "    'left': {'type': 'leaf', 'class': np.int64(1)},\n",
       "    'right': {'type': 'leaf', 'class': np.int64(0)}},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 1,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 2,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 0,\n",
       "   'left': {'type': 'node',\n",
       "    'feature_index': 2,\n",
       "    'left': {'type': 'leaf', 'class': np.int64(1)},\n",
       "    'right': {'type': 'leaf', 'class': np.int64(0)}},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 2,\n",
       "  'left': {'type': 'node',\n",
       "   'feature_index': 1,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       "  'right': {'type': 'leaf', 'class': np.int64(1)}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 2,\n",
       "  'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "  'right': {'type': 'node',\n",
       "   'feature_index': 0,\n",
       "   'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "   'right': {'type': 'leaf', 'class': np.int64(1)}}},\n",
       " {'type': 'node',\n",
       "  'feature_index': 2,\n",
       "  'left': {'type': 'leaf', 'class': np.int64(0)},\n",
       "  'right': {'type': 'leaf', 'class': np.int64(1)}}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it out\n",
    "rf = RandomForestClassifier(20,4)\n",
    "rf.fit(X_train,y_train)\n",
    "rf.trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6f02eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [1 1 0 0 1 0 0 1 1 0]\n",
      "actual: [1 1 0 0 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "## 这里没有用到交叉验证\n",
    "print(\"result:\",rf.predict(X_train))\n",
    "print(\"actual:\",y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
